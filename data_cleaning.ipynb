{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "TKpGIoPB0VLC"
      },
      "outputs": [],
      "source": [
        "# Web scraping, pickle imports\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pickle\n",
        "\n",
        "# Scrapes transcript data from scrapsfromtheloft.com\n",
        "def url_to_transcript(url):\n",
        "    '''Returns transcript data specifically from scrapsfromtheloft.com.'''\n",
        "    page = requests.get(url).text\n",
        "    soup = BeautifulSoup(page, \"lxml\")\n",
        "    text = [p.text for p in soup.find(class_=\"post-content\").find_all('p')]\n",
        "    print(url)\n",
        "    return text\n",
        "\n",
        "# URLs of transcripts in scope\n",
        "urls = ['http://scrapsfromtheloft.com/2017/05/06/louis-ck-oh-my-god-full-transcript/',\n",
        "        'http://scrapsfromtheloft.com/2017/04/11/dave-chappelle-age-spin-2017-full-transcript/',\n",
        "        'http://scrapsfromtheloft.com/2018/03/15/ricky-gervais-humanity-transcript/',\n",
        "        'http://scrapsfromtheloft.com/2017/08/07/bo-burnham-2013-full-transcript/',\n",
        "        'http://scrapsfromtheloft.com/2017/05/24/bill-burr-im-sorry-feel-way-2014-full-transcript/',\n",
        "        'http://scrapsfromtheloft.com/2017/04/21/jim-jefferies-bare-2014-full-transcript/',\n",
        "        'http://scrapsfromtheloft.com/2017/08/02/john-mulaney-comeback-kid-2015-full-transcript/',\n",
        "        'http://scrapsfromtheloft.com/2017/10/21/hasan-minhaj-homecoming-king-2017-full-transcript/',\n",
        "        'http://scrapsfromtheloft.com/2017/09/19/ali-wong-baby-cobra-2016-full-transcript/',\n",
        "        'http://scrapsfromtheloft.com/2017/08/03/anthony-jeselnik-thoughts-prayers-2015-full-transcript/',\n",
        "        'http://scrapsfromtheloft.com/2018/03/03/mike-birbiglia-my-girlfriends-boyfriend-2013-full-transcript/',\n",
        "        'http://scrapsfromtheloft.com/2017/08/19/joe-rogan-triggered-2016-full-transcript/']\n",
        "\n",
        "# Comedian names\n",
        "comedians = ['louis', 'dave', 'ricky', 'bo', 'bill', 'jim', 'john', 'hasan', 'ali', 'anthony', 'mike', 'joe']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "PUujSrN30VLI"
      },
      "outputs": [],
      "source": [
        "# Load pickled files\n",
        "data = {}\n",
        "for i, c in enumerate(comedians):\n",
        "    with open(\".txt\", \"rb\") as file:\n",
        "        data[c] = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXdCBYLz0VLJ"
      },
      "outputs": [],
      "source": [
        "# Double check to make sure data has been loaded properly\n",
        "data.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBa7yM5R0VLK"
      },
      "outputs": [],
      "source": [
        "# More checks\n",
        "data['louis'][:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QjMLZX30VLM"
      },
      "outputs": [],
      "source": [
        "# Let's take a look at our data again\n",
        "next(iter(data.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPmv5_qA0VLN"
      },
      "outputs": [],
      "source": [
        "# Notice that our dictionary is currently in key: comedian, value: list of text format\n",
        "next(iter(data.values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "hMkir-Qc0VLO"
      },
      "outputs": [],
      "source": [
        "# We are going to change this to key: comedian, value: string format\n",
        "def combine_text(list_of_text):\n",
        "    '''Takes a list of text and combines them into one large chunk of text.'''\n",
        "    combined_text = ' '.join(list_of_text)\n",
        "    return combined_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ZV6IgZv80VLP"
      },
      "outputs": [],
      "source": [
        "# Combine it!\n",
        "data_combined = {key: [combine_text(value)] for (key, value) in data.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ioq20kxi0VLP"
      },
      "outputs": [],
      "source": [
        "# We can either keep it in dictionary format or put it into a pandas dataframe\n",
        "import pandas as pd\n",
        "pd.set_option('max_colwidth',150)\n",
        "\n",
        "data_df = pd.DataFrame.from_dict(data_combined).transpose()\n",
        "data_df.columns = ['transcript']\n",
        "data_df = data_df.sort_index()\n",
        "data_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lhbt0ViX0VLQ"
      },
      "outputs": [],
      "source": [
        "# Let's take a look at the transcript for Ali Wong\n",
        "data_df.transcript.loc['ali']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-MLCtTlJ0VLQ"
      },
      "outputs": [],
      "source": [
        "# Apply a first round of text cleaning techniques\n",
        "import re\n",
        "import string\n",
        "\n",
        "def clean_text_round1(text):\n",
        "    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
        "    text = text.lower()\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    return text\n",
        "\n",
        "round1 = lambda x: clean_text_round1(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aX4R3KE0VLR"
      },
      "outputs": [],
      "source": [
        "# Let's take a look at the updated text\n",
        "data_clean = pd.DataFrame(data_df.transcript.apply(round1))\n",
        "data_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "VQz9a8rQ0VLR"
      },
      "outputs": [],
      "source": [
        "# Apply a second round of cleaning\n",
        "def clean_text_round2(text):\n",
        "    '''Get rid of some additional punctuation and non-sensical text that was missed the first time around.'''\n",
        "    text = re.sub('[‘’“”…]', '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    return text\n",
        "\n",
        "round2 = lambda x: clean_text_round2(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTG830gt0VLS"
      },
      "outputs": [],
      "source": [
        "# Let's take a look at the updated text\n",
        "data_clean = pd.DataFrame(data_clean.transcript.apply(round2))\n",
        "data_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bih9uaeG0VLV"
      },
      "outputs": [],
      "source": [
        "# Let's take a look at our dataframe\n",
        "data_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbDdt0Bq0VLV"
      },
      "outputs": [],
      "source": [
        "# Let's add the comedians' full names as well\n",
        "full_names = ['Ali Wong', 'Anthony Jeselnik', 'Bill Burr', 'Bo Burnham', 'Dave Chappelle', 'Hasan Minhaj',\n",
        "              'Jim Jefferies', 'Joe Rogan', 'John Mulaney', 'Louis C.K.', 'Mike Birbiglia', 'Ricky Gervais']\n",
        "\n",
        "data_df['full_name'] = full_names\n",
        "data_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "NVntRgkX0VLW"
      },
      "outputs": [],
      "source": [
        "# Let's pickle it for later use\n",
        "data_df.to_pickle(\"corpus.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1U0Nc-kh0VLX"
      },
      "outputs": [],
      "source": [
        "# We are going to create a document-term matrix using CountVectorizer, and exclude common English stop words\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cv = CountVectorizer(stop_words='english')\n",
        "data_cv = cv.fit_transform(data_clean.transcript)\n",
        "data_dtm = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
        "data_dtm.index = data_clean.index\n",
        "data_dtm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "8Tr1IElG0VLX"
      },
      "outputs": [],
      "source": [
        "# Let's pickle it for later use\n",
        "data_dtm.to_pickle(\"dtm.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "lYTrwein0VLY"
      },
      "outputs": [],
      "source": [
        "# Let's also pickle the cleaned data (before we put it in document-term matrix format) and the CountVectorizer object\n",
        "data_clean.to_pickle('data_clean.pkl')\n",
        "pickle.dump(cv, open(\"cv.pkl\", \"wb\"))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "1-Data-Cleaning.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}